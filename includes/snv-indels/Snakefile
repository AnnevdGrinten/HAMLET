include: "common.smk"


localrules:
    filter_vep,
    final_bamfile,


rule all:
    input:
        bam=[module_output.bam(sample) for sample in samples],
        bai=[module_output.bai(sample) for sample in samples],
        filter_vep=[module_output.filter_vep(sample) for sample in samples],
        json=[module_output.json(sample) for sample in samples],
        hotspot=[module_output.hotspot(sample) for sample in samples],
        multiqc="multiqc_snv_indels.html",


rule tmpdir:
    output:
        temporary(directory("snv-indel-tmp")),
    container:
        containers["vardict"]
    log:
        "log/tmpdir.txt",
    shell:
        """
        mkdir -p {output} 2> {log}
        """


rule call_regions:
    """Determine the regions to call from the GTF file"""
    input:
        fasta=config["genome_fasta"],
        gtf=config["gtf"],
        src=srcdir("scripts/create_bed.sh"),
    output:
        # Intermediate files from the bash script
        chroms=temporary("chroms.txt"),
        all_genes=temporary("all_genes.bed"),
        # Final bed file
        bed=temporary("call_regions.bed"),
    log:
        "log/call_regions.txt",
    container:
        containers["bedtools-2.27-grep-2.14-gawk-5.0-python-3.7"]
    shell:
        """
        bash {input.src} {input.fasta} {input.gtf} > {output.bed} 2> {log}
        """


rule align_vars:
    input:
        fq1=get_forward,
        fq2=get_reverse,
        index=config["star_index"],
        gtf=config["gtf"],
    output:
        bam=temporary("{sample}/snv-indels/Aligned.sortedByCoord.out.bam"),
        gene_count="{sample}/snv-indels/{sample}.ReadsPerGene.out.tab",
    params:
        rg_sample=lambda wildcards: wildcards.sample,
        chim_segment=20,
        min_intron_size=50,
        alignInsertionFlush="Right",
        twopassMode="Basic",
        outBAMsortingBinsN=100,
    log:
        main="{sample}/snv-indels/Log.out",
        progress="{sample}/snv-indels/Log.progress.out",
        final="{sample}/snv-indels/Log.final.out",
    threads: 8
    container:
        containers["star"]
    shell:
        """
        STAR \
            --runThreadN {threads} \
            --genomeDir {input.index} \
            --sjdbGTFfile {input.gtf} \
            --readFilesCommand zcat \
            --outSAMattrRGline "ID:{params.rg_sample}" "SM:{params.rg_sample}" \
            --outFileNamePrefix $(dirname {output.bam})/ \
            --outSAMtype BAM SortedByCoordinate \
            --outSAMunmapped Within \
            --alignIntronMin {params.min_intron_size} \
            --alignInsertionFlush {params.alignInsertionFlush} \
            --twopassMode {params.twopassMode} \
            --chimOutType WithinBAM \
            --chimSegmentMin {params.chim_segment} \
            --quantMode GeneCounts \
            --outBAMsortingBinsN {params.outBAMsortingBinsN} \
            --readFilesIn {input.fq1:q} {input.fq2:q}

        # Rename the count file to include the sample name
        mv {wildcards.sample}/snv-indels/ReadsPerGene.out.tab {output.gene_count}

        # Remove temporary files that STAR leaves all over the place
        rm -rf {wildcards.sample}/snv-indels/_STAR*
        """


rule index_bamfile:
    input:
        bam="{sample}/snv-indels/Aligned.sortedByCoord.out.bam",
        tmp=rules.tmpdir.output,
    output:
        bai=temporary("{sample}/snv-indels/Aligned.sortedByCoord.out.bam.bai"),
    log:
        "log/index_bamfile.{sample}.txt",
    container:
        containers["varscan-2.4.2-samtools-1.3.1-tabix-0.2.6-grep-2.14"]
    shell:
        """
        samtools index {input.bam} 2> {log}
        """


rule final_bamfile:
    """Create the final bam file"""
    input:
        bam="{sample}/snv-indels/Aligned.sortedByCoord.out.bam",
        bai="{sample}/snv-indels/Aligned.sortedByCoord.out.bam.bai",
    output:
        bam="{sample}/snv-indels/{sample}.bam",
        bai="{sample}/snv-indels/{sample}.bam.bai",
    log:
        "log/final_bamfile.{sample}.txt",
    container:
        containers["picard"]
    shell:
        """
        ln {input.bam} {output.bam} 2> {log}
        ln {input.bai} {output.bai} 2>> {log}
        """


rule genome_txt:
    input:
        ref_dict=config["genome_dict"],
    output:
        genome=temp(".tmp.genome.txt"),
    log:
        "log/tmp.genome.txt",
    container:
        containers["varscan-2.4.2-samtools-1.3.1-tabix-0.2.6-grep-2.14"]
    shell:
        """
        cat {input.ref_dict} \
        | grep -P "@SQ\\tSN:" \
        | sed 's/@SQ\\tSN://' \
        | sed 's/\\tLN:/\\t/' \
        | cut -f1,2 \
        > {output.genome} 2> {log}
        """


rule exon_cov_ref:
    input:
        ref_fai=config["genome_fai"],
        ref_refflat=config["annotation_refflat"],
    output:
        bed=temp(".tmp.exon_cov_ref.bed"),
    log:
        "log/exon_cov_ref.txt",
    container:
        containers["bedtools-2.27-grep-2.14-gawk-5.0-python-3.7"]
    shell:
        """
        cat {input.ref_refflat} \
         | grep -vP "chr.*(alt|random|fix)\t" \
         | awk \'{{ split($10, starts, ","); split($11, ends, ","); for (i=1; i < length(starts); i++) {{ print $3"\\t"starts[i]"\\t"ends[i]"\\t"gensub(/(\.[0-9]+)/,"", "g", $2)"\\t"i"\\t"$4 }} }}\' \
         | bedtools sort -faidx {input.ref_fai} \
         > {output.bed} 2> {log}
        """


rule exon_cov:
    input:
        bam=module_output.bam,
        bai=module_output.bai,
        bed=".tmp.exon_cov_ref.bed",
        genome=".tmp.genome.txt",
        idm=config["ref_id_mapping"],
        scr=srcdir("scripts/aggr_exon_cov.py"),
    output:
        json="{sample}/snv-indels/{sample}.exon_cov_stats.json",
    log:
        "log/exon_cov.{sample}.txt",
    container:
        containers["bedtools-2.27-grep-2.14-gawk-5.0-python-3.7"]
    shell:
        """
        bedtools coverage \
            -d \
            -sorted \
            -g {input.genome} \
            -a {input.bed} \
            -b {input.bam} 2> {log} \
        | cut -f1,2,3,4,5,8,7 \
        | python {input.scr} \
            --id-mapping {input.idm} - {output.json} 2> {log}
        """


rule call_vars:
    input:
        bam=module_output.bam,
        bai=module_output.bai,
        ref=config["genome_fasta"],
        bed=rules.call_regions.output.bed,
        tmp=rules.tmpdir.output,
    output:
        vcf="{sample}/snv-indels/{sample}.raw.vcf.gz",
    params:
        min_af=0.05,
        bed_chrom=1,
        bed_start=2,
        bed_end=3,
        bed_gene=4,
    log:
        vardict="log/vardict.{sample}.txt",
        strandbias="log/strandbias.{sample}.txt",
        var2vcf="log/var2vcf.{sample}.txt",
        gzip="log/gzip.{sample}.txt",
    threads: 3
    container:
        containers["vardict"]
    shell:
        """
        export TMPDIR={input.tmp}

        vardict-java \
            -G {input.ref} \
            -N {wildcards.sample} \
            -b {input.bam} \
            -f {params.min_af} \
            -c {params.bed_chrom} \
            -S {params.bed_start} \
            -E {params.bed_end} \
            -g {params.bed_gene} \
            --verbose \
            {input.bed} 2> {log.vardict} \
            |
        teststrandbias.R 2> {log.strandbias} \
            |
        var2vcf_valid.pl -A 2> {log.var2vcf} \
            |
        gzip > {output.vcf} 2> {log.gzip}
        """


rule aln_stats:
    input:
        bam=module_output.bam,
        bai=module_output.bai,
        ref=config["genome_fasta"],
        ref_dict=config["genome_dict"],
    output:
        stats="{sample}/snv-indels/{sample}.aln_stats",
    log:
        "log/aln_stats.{sample}.txt",
    threads: 1
    container:
        containers["picard"]
    shell:
        """
        picard -Xmx4G CollectAlignmentSummaryMetrics \
            VALIDATION_STRINGENCY=LENIENT \
            R={input.ref} \
            I={input.bam} \
            USE_JDK_DEFLATER=true \
            USE_JDK_INFLATER=true \
            O={output.stats} 2> {log}

        """


rule insert_stats:
    input:
        bam=module_output.bam,
        bai=module_output.bai,
        ref=config["genome_fasta"],
        ref_dict=config["genome_dict"],
    output:
        stats="{sample}/snv-indels/{sample}.insert_stats",
        histo="{sample}/snv-indels/{sample}.insert_stats.pdf",
    log:
        "log/insert_stats.{sample}.txt",
    threads: 1
    container:
        containers["picard"]
    shell:
        """
        picard -Xmx4G CollectInsertSizeMetrics \
            VALIDATION_STRINGENCY=LENIENT \
            R={input.ref} \
            I={input.bam} \
            O={output.stats} \
            USE_JDK_DEFLATER=true \
            USE_JDK_INFLATER=true \
            H={output.histo} 2> {log}
        """


rule rna_stats:
    """Note: if no reads overlap the annotation_refflat, no output is produced"""
    input:
        bam=module_output.bam,
        bai=module_output.bai,
        ref=config["genome_fasta"],
        ref_dict=config["genome_dict"],
        ref_rrna=config["rrna_refflat"],
        annot=config["annotation_refflat"],
    output:
        stats="{sample}/snv-indels/{sample}.rna_stats",
        histo="{sample}/snv-indels/{sample}.rna_stats.pdf",
    log:
        "log/rna_stats.{sample}.txt",
    threads: 1
    container:
        containers["picard"]
    shell:
        """
        picard -Xmx4G CollectRnaSeqMetrics \
             VALIDATION_STRINGENCY=LENIENT \
             R={input.ref} \
             REF_FLAT={input.annot} \
             RIBOSOMAL_INTERVALS={input.ref_rrna} \
             STRAND_SPECIFICITY=NONE \
             ASSUME_SORTED=true \
             CHART_OUTPUT={output.histo} \
             I={input.bam} \
             USE_JDK_DEFLATER=true \
             USE_JDK_INFLATER=true \
             O={output.stats} 2> {log}
        """


rule annotate_vars:
    """Annotate variants using VEP"""
    input:
        vcf="{sample}/snv-indels/{sample}.raw.vcf.gz",
        genome_fasta=config["genome_fasta"],
    params:
        online="" if config.get("vep_cache") else "--database",
        offline=(
            f" --offline --cache_version 108 --everything --merged --dir {config['vep_cache']}"
            if config.get("vep_cache")
            else ""
        ),
    output:
        vep="{sample}/snv-indels/{sample}.vep.txt.gz",
        stats="{sample}/snv-indels/{sample}.vep_stats.txt",
    log:
        "log/annotate_vars.{sample}.txt",
    threads: 8
    container:
        containers["vep"]
    shell:
        """
        vep \
            -i {input.vcf} \
            --fasta {input.genome_fasta} \
            {params.online} \
            {params.offline} \
            --fork {threads} \
            --allele_number --stats_text --json --force_overwrite --assembly GRCh38 \
            --format vcf \
            --polyphen b \
            --sift b \
            --hgvs \
            --numbers \
            --stats_file {output.stats} \
            --output_file STDOUT | gzip > {output.vep}\
            2> {log}
        """


rule hotspot_variants:
    input:
        vcf="{sample}/snv-indels/{sample}.raw.vcf.gz",
        bed=config["bed_variant_hotspots"],
    output:
        vcf="{sample}/snv-indels/{sample}.hotspot.vcf",
    log:
        "log/hotspot_variants.{sample}.txt",
    threads: 1
    container:
        containers["bedtools-2.27-grep-2.14-gawk-5.0-python-3.7"]
    shell:
        """
        bedtools intersect \
            -a {input.vcf} \
            -b {input.bed} \
            -header \
            > {output.vcf} 2> {log}
        """


rule filter_vep:
    input:
        vep="{sample}/snv-indels/{sample}.vep.txt.gz",
        ref_id_mapping=config["ref_id_mapping"],
        hotspots="{sample}/snv-indels/{sample}.hotspot.vcf",
        scr=srcdir("scripts/filter_vep.py"),
        blacklist=config.get("blacklist", []),
    params:
        vep_consequences=config["vep_include_consequence"],
        blacklist=f"--blacklist {config['blacklist']}" if "blacklist" in config else "",
        population="gnomade",
        max_pop_af=0.01,
    output:
        filtered="{sample}/snv-indels/{sample}.vep.filtered.txt.gz",
    log:
        "log/filter_vep.{sample}.txt",
    threads: 1
    container:
        containers["crimson"]
    shell:
        """
        python3 {input.scr} \
            {input.vep} \
            {input.ref_id_mapping} \
            --hotspot {input.hotspots} \
            --consequences {params.vep_consequences} \
            --population {params.population} \
            --frequency {params.max_pop_af} \
            {params.blacklist} \
            | gzip > {output.filtered} 2> {log}
        """


rule json_output:
    input:
        id_mappings_path=config["ref_id_mapping"],
        filter_vep=module_output.filter_vep,
        aln_stats="{sample}/snv-indels/{sample}.aln_stats",
        rna_stats="{sample}/snv-indels/{sample}.rna_stats",
        insert_stats="{sample}/snv-indels/{sample}.insert_stats",
        exon_cov_stats="{sample}/snv-indels/{sample}.exon_cov_stats.json",
        vep_stats="{sample}/snv-indels/{sample}.vep_stats.txt",
        src=srcdir("scripts/json-output.py"),
    output:
        "{sample}/snv-indels/snv-indels-output.json",
    log:
        "log/snv_indels_output.{sample}.txt",
    container:
        containers["crimson"]
    shell:
        """
        python3 {input.src} \
            {input.id_mappings_path} \
            --vep_txt {input.filter_vep} \
            --aln_stats_path {input.aln_stats} \
            --rna_stats_path {input.rna_stats} \
            --insert_stats_path {input.insert_stats} \
            --exon_cov_stats_path {input.exon_cov_stats} \
            --vep_stats_path {input.vep_stats} > {output} 2> {log}
        """


rule multiqc:
    input:
        stats=module_output.multiqc_files,
        config=srcdir("../../cfg/multiqc.yml"),
    params:
        filelist="multiqc_filelist_snv_indels.txt",
        depth=2,
        modules=multiqc_modules(),
    output:
        html="multiqc_snv_indels.html",
    log:
        "log/snv_indels.multiqc.txt",
    container:
        containers["multiqc"]
    shell:
        """
        rm -f {params.filelist}

        for fname in {input.stats}; do
            echo $fname >> {params.filelist}
        done

        multiqc \
        --force \
        --dirs \
        --dirs-depth {params.depth} \
        --fullnames \
        --fn_as_s_name \
        --file-list {params.filelist} \
        --config {input.config} \
        {params.modules} \
        --filename {output.html} 2> {log}
        """
