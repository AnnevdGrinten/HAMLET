from rattle import Run
from os import path

RUN = Run(config)

# TODO: ensure db indices exist
RUN.set_default_setting("genome_dict", RUN.settings["genome_fasta"].rsplit(".", 1)[0] + ".dict")
RUN.set_default_setting("extract_script", srcdir(path.join("scripts", "vcf2json.py")))
RUN.set_default_setting("csv_script", srcdir(path.join("scripts", "json2csv.py")))
RUN.set_default_setting("plot_script", srcdir(path.join("scripts", "plotVariants.R")))
RUN.set_default_setting("exon_cov_script", srcdir(path.join("scripts", "aggr_exon_cov.py")))
RUN.set_default_setting("genome_fai", RUN.settings["genome_fasta"] + ".fai")

containers = {
    "bedtools": "docker://quay.io/biocontainers/bedtools:2.23.0--hdbcaa40_3",
    "debian": "docker://debian:buster-slim",
    "gsnap": "docker://quay.io/biocontainers/gmap:2019.06.10--pl526h2f06484_0",
    # Wait for the mulled container
    # https://github.com/BioContainers/multi-package-containers/pull/838
    # click=7.0,pyvcf=0.6.8,python=3.5
    "test": "docker://quay.io/biocontainers/mulled-v2-0a61039b60060e63b68e2f161289f029150f86c3:d29da2f35209ab08fa8cd60a29118dd759209458-0",
    "picard": "docker://quay.io/biocontainers/picard:2.20.5--0",
    "python3": "docker://python:3.7.4-slim-stretch",
    "R": "docker://quay.io/biocontainers/r:3.2.2--0",
    "samtools": "docker://quay.io/biocontainers/samtools:1.6--h244ad75_4",
    # varscan=2.4.3,samtools=1.6,tabix=0.2.6
    "varscan": "docker://quay.io/biocontainers/mulled-v2-fe04a5388a5c60964bedfc046450b83c0d810523:7ddebf6ed147098f06e2d2c7e0e6c89c9cee9978-0",
    "vep": "docker://quay.io/biocontainers/ensembl-vep:97.3--pl526hecc5488_0"
}

rule all_snv_indels:
    input:
        #plots_mark=expand(RUN.output("{sample}/snv-indels/variant_plots/.done"), sample=RUN.samples),
        plotd=expand(RUN.output("{sample}/snv-indels/variant_plots"), sample=RUN.samples),


if RUN.settings.get("gsnap_exe") is not None:
    # To reproduce paper results, relies on a non-conda GSNAP 2014.12.23 with SIMD
    rule align_vars:
        input:
            fq1=RUN.output("{sample}/{sample}-R1.fq.gz"),
            fq2=RUN.output("{sample}/{sample}-R2.fq.gz"),
            index=RUN.settings["genome_gmap_index"],
            #exe=RUN.settings["gsnap_exe"],
        output:
            sam=temp(RUN.output("{sample}/snv-indels/{sample}.snv-indel.raw.sam")),
            #bai=temp(RUN.output("{sample}/snv-indels/{sample}.snv-indel.raw.bai")),
        params:
            rg_sample="{sample}"
        threads: 8
        conda: srcdir("envs/align_vars.yml")
        singularity: containers["gsnap"]
        shell:
            #"{input.exe} --dir `dirname {input.index}` --db `basename {input.index}`"
            "gsnap --dir `dirname {input.index}` --db `basename {input.index}`"
            " --batch 4 --nthreads {threads}"
            " --novelsplicing 1 --npaths 1 --quiet-if-excessive"
            " --read-group-name={params.rg_sample} --read-group-id={params.rg_sample}"
            " --format sam --gunzip {input.fq1} {input.fq2} > {output.sam}"

    rule sort_bamfile:
        input:
            sam=RUN.output("{sample}/snv-indels/{sample}.snv-indel.raw.sam"),
        output:
            bam=temp(RUN.output("{sample}/snv-indels/{sample}.snv-indel.sort.bam")),
            bai=temp(RUN.output("{sample}/snv-indels/{sample}.snv-indel.sort.bai")),
        singularity: containers["picard"]
        shell:
            "picard SortSam I={input.sam} O={output.bam} SORT_ORDER=coordinate "
            "VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true "


    rule reorder_aln_header:
        input:
            bam=RUN.output("{sample}/snv-indels/{sample}.snv-indel.sort.bam"),
            bai=RUN.output("{sample}/snv-indels/{sample}.snv-indel.sort.bai"),
            ref=RUN.settings["genome_fasta"],
            refd=RUN.settings["genome_dict"],
        output:
            bam=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bam"),
            bai=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bai"),
        params:
            rg_sample="{sample}"
        threads: 1
        conda: srcdir("envs/align_vars.yml")
        singularity: containers["picard"]
        shell:
            "picard -Xmx3G ReorderSam I={input.bam} O={output.bam} R={input.ref}"
            " VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true"
else:
    rule align_vars:
        input:
            fq1=RUN.output("{sample}/{sample}-R1.fq.gz"),
            fq2=RUN.output("{sample}/{sample}-R2.fq.gz"),
            index=RUN.settings["genome_star_index"],
        output:
            bam=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bam"),
            bai=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bai"),
        params:
            rg_sample="{sample}"
        threads: 8
        conda: srcdir("envs/align_vars.yml")
        shell:
            "rm -rf `dirname {output.bam}`/alignment && "
            "mkdir -p `dirname {output.bam}`/alignment && "
            "STAR --outFileNamePrefix `dirname {output.bam}`/alignment/"
            " --genomeDir {input.index} --readFilesIn {input.fq1} {input.fq2}"
            " --readFilesCommand zcat --runThreadN {threads}"
            " --outStd SAM --outSAMunmapped Within --outFilterMultimapNmax 1"
            " --outSAMattrRGline ID:{params.rg_sample} SM:{params.rg_sample}"
            " | picard SortSam I=/dev/stdin O={output.bam} SORT_ORDER=coordinate"
            " VALIDATION_STRINGENCY=SILENT CREATE_INDEX=true"

rule genome_txt:
    input:
        ref_dict=RUN.settings["genome_dict"],
    output:
        genome=temp(RUN.output(".tmp.genome.txt"))
    singularity: containers["debian"]
    shell:
        " cat {input.ref_dict}"
        " | grep -P \"@SQ\\tSN:\""
        " | sed 's/@SQ\\tSN://'"
        " | sed 's/\\tLN:/\\t/'"
        " | cut -f1,2"
        " > {output.genome}"

rule exon_cov_ref:
    input:
        ref_fai=RUN.settings["genome_fai"],
        ref_refflat=RUN.settings["annotation_refflat"],
    output:
        bed=temp(RUN.output(".tmp.exon_cov_ref.bed"))
    conda: srcdir("envs/exon_covs.yml")
    singularity: containers["bedtools"]
    shell:
        "cat {input.ref_refflat}"
        " | grep -vP \"chr.*alt\t\""
        " | awk '{{ split($10, starts, \",\"); split($11, ends, \",\"); for (i=1; i < length(starts); i++) {{ print $3\"\\t\"starts[i]\"\\t\"ends[i]\"\\t\"gensub(/(\.[0-9]+)/,\"\", \"g\", $2)\"\\t\"i\"\\t\"$4 }} }}'"
        " | bedtools sort -faidx {input.ref_fai}"
        " > {output.bed}"

rule exon_cov:
    input:
        bam=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bam"),
        bed=RUN.output(".tmp.exon_cov_ref.bed"),
        genome=RUN.output(".tmp.genome.txt"),
        idm=RUN.settings["ref_id_mapping"],
        scr=RUN.settings["exon_cov_script"]
    output:
        json=RUN.output("{sample}/snv-indels/{sample}.exon_cov_stats.json")
    conda: srcdir("envs/exon_covs.yml")
    singularity: containers["bedtools"]
    shell:
        "bedtools coverage -d -sorted -g {input.genome} -a {input.bed} -b {input.bam}"
        " | cut -f1,2,3,4,5,8,7"
        " | python {input.scr} --id-mapping {input.idm} - {output.json}"

rule call_vars:
    input:
        bam=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bam"),
        ref=RUN.settings["genome_fasta"],
    output:
        vcf=RUN.output("{sample}/snv-indels/{sample}.raw.vcf.gz")
    threads: 3
    conda: srcdir("envs/call_vars.yml")
    singularity: containers["varscan"]
    shell:
        "samtools mpileup -f {input.ref} -d 1000000 -s -B {input.bam}"
        " | grep -vE '\\t\\t'"
        " | varscan mpileup2cns --strand-filter 0 --output-vcf 1 --min-var-freq 0.1 --p-value 0.05"
        " | grep -vE '\\t\./\.|\\t0/0'"
        " | bgzip -c > {output.vcf}"

rule aln_stats:
    input:
        bam=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bam"),
        bai=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bai"),
        ref=RUN.settings["genome_fasta"],
        ref_dict=RUN.settings["genome_dict"],
    output:
        stats=RUN.output("{sample}/snv-indels/{sample}.aln_stats")
    threads: 1
    conda: srcdir("envs/bam_stats.yml")
    singularity: containers["picard"]
    shell:
        "picard -Xmx2G CollectAlignmentSummaryMetrics"
        " R={input.ref} I={input.bam} O={output.stats}"

rule insert_stats:
    input:
        bam=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bam"),
        bai=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bai"),
        ref=RUN.settings["genome_fasta"],
        ref_dict=RUN.settings["genome_dict"],
    output:
        stats=RUN.output("{sample}/snv-indels/{sample}.insert_stats"),
        histo=RUN.output("{sample}/snv-indels/{sample}.insert_stats.pdf")
    threads: 1
    conda: srcdir("envs/bam_stats.yml")
    singularity: containers["picard"]
    shell:
        "picard -Xmx2G CollectInsertSizeMetrics"
        " R={input.ref} I={input.bam} O={output.stats} H={output.histo}"

rule rna_stats:
    input:
        bam=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bam"),
        bai=RUN.output("{sample}/snv-indels/{sample}.snv-indel.bai"),
        ref=RUN.settings["genome_fasta"],
        ref_dict=RUN.settings["genome_dict"],
        ref_rrna=RUN.settings["rrna_refflat"],
        annot=RUN.settings["annotation_refflat"],
    output:
        stats=RUN.output("{sample}/snv-indels/{sample}.rna_stats")
    threads: 1
    conda: srcdir("envs/bam_stats.yml")
    singularity: containers["picard"]
    shell:
        "picard -Xmx4G CollectRnaSeqMetrics"
        " R={input.ref} REF_FLAT={input.annot}"
        " RIBOSOMAL_INTERVALS={input.ref_rrna}"
        " STRAND_SPECIFICITY=NONE ASSUME_SORTED=true"
        " CHART_OUTPUT={output.stats}.pdf I={input.bam} O={output.stats}"

rule annotate_vars:
    input:
        vcf=RUN.output("{sample}/snv-indels/{sample}.raw.vcf.gz"),
        ref_1kg=RUN.settings["vcf_1kg"],
        ref_gonl=RUN.settings["vcf_gonl"],
        cache_vep=RUN.settings["cache_vep"],
        fasta_vep=RUN.settings["fasta_vep"],
    output:
        vcf=RUN.output("{sample}/snv-indels/{sample}.annotated.vcf.gz"),
        stats=RUN.output("{sample}/snv-indels/{sample}.vep_stats"),
    threads: 8
    singularity: containers["vep"]
    shell:
        "vep -i {input.vcf}"
        " --fasta {input.fasta_vep} --dir {input.cache_vep}"
        " --custom {input.ref_1kg},P3,vcf,exact,0,AF,AFR_AF,AMR_AF,EAS_AF,EUR_AF,SAS_AF"
        " --custom {input.ref_gonl},GONL,vcf,exact,0,AF"
        " --fork {threads} --offline --cache_version 97 --assembly GRCh38 --everything --merged"
        " --allele_number --stats_text --vcf --cache --force_overwrite"
        " --stats_file {output.stats} -o STDOUT | bgzip -c > {output.vcf}"

rule extract_vars:
    input:
        vcf=RUN.output("{sample}/snv-indels/{sample}.annotated.vcf.gz"),
        ref_hotspots=RUN.settings["bed_variant_hotspots"],
        ref_id_mapping=RUN.settings["ref_id_mapping"],
        scr=RUN.settings["extract_script"],
    output:
        json=RUN.output("{sample}/snv-indels/{sample}.variants.json"),
    threads: 1
    conda: srcdir("envs/extract_vars.yml")
    singularity: containers["test"]
    shell:
        "python {input.scr} --hotspots {input.ref_hotspots} --sample-id {wildcards.sample}"
        " {input.ref_id_mapping} {input.vcf} > {output.json}"

rule table_vars_all:
    input:
        json=RUN.output("{sample}/snv-indels/{sample}.variants.json"),
        scr=RUN.settings["csv_script"],
    output:
        csv=RUN.output("{sample}/snv-indels/{sample}.variants_all.csv"),
    threads: 1
    conda: srcdir("envs/json_to_csv.yml")
    singularity: containers["python3"]
    shell:
        "python {input.scr} {input.json} > {output.csv}"

rule table_vars_hi:
    input:
        json=RUN.output("{sample}/snv-indels/{sample}.variants.json"),
        scr=RUN.settings["csv_script"],
    output:
        csv=RUN.output("{sample}/snv-indels/{sample}.variants_hi.csv"),
    threads: 1
    conda: srcdir("envs/json_to_csv.yml")
    singularity: containers["python3"]
    shell:
        "python {input.scr} --hi {input.json} > {output.csv}"

rule plot_vars:
    input:
        json=RUN.output("{sample}/snv-indels/{sample}.variants.json"),
        scr=RUN.settings["plot_script"],
        ref_id_mapping=RUN.settings["ref_id_mapping"],
        ref_hotspots=RUN.settings["bed_variant_hotspots"],
        ref_amplicons=RUN.settings["ref_amplicons"],
        ref_annot_goi=RUN.settings["ref_annot_goi"],
    params:
        plotd=RUN.output("{sample}/snv-indels/variant_plots"),
    output:
        #plots_mark=RUN.output("{sample}/snv-indels/variant_plots/.done"),
        plotd=directory(RUN.output("{sample}/snv-indels/variant_plots"))
    threads: 1
    conda: srcdir("envs/plot_variants.yml")
    singularity: containers["R"]
    shell:
        "(Rscript {input.scr} -j {input.json}"
        " -i {input.ref_id_mapping} -m {input.ref_annot_goi}"
        " -a {input.ref_amplicons} -t {input.ref_hotspots}"
        " -o `dirname {params.plotd}` && touch {params.plotd}/.done)"
        " || rm -rf {params.plotd}"
