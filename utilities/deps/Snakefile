import os

# TODO
# - remove scrdir
# - add option to specify output folder
containers = {
    "arriba": "docker://quay.io/biocontainers/arriba:2.4.0--h0033a41_2",
    "hamlet-scripts": "docker://lumc/hamlet-scripts:0.3",
    "debian": "docker://debian:buster-slim",
    "samtools": "docker://quay.io/biocontainers/samtools:1.6--h244ad75_4",
    "ucsc-gtftogenepred": "docker://quay.io/biocontainers/ucsc-gtftogenepred:377--ha8a8165_5",
    "star": "docker://quay.io/biocontainers/star:2.7.10b--h9ee0642_0",
    "picard": "docker://quay.io/biocontainers/picard:2.27.4--hdfd78af_0",
    "vep": "docker://quay.io/biocontainers/ensembl-vep:108.2--pl5321h4a94de4_0",
    "zip": "docker://lumc/zip:3.0",
}

VEP_RELEASE = 108

settings = {
    "arriba": "docker://quay.io/biocontainers/arriba:2.4.0--h0033a41_2",
    "reference_url": "ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz",
    "reference_fai": "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.fai",
    "refflat": "http://hgdownload.cse.ucsc.edu/goldenpath/hg38/database/refFlat.txt.gz",
    #'gtf': 'https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/genes/hg38.ensGene.gtf.gz'
    # "gtf": "https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_41/gencode.v41.annotation.gtf.gz",
    "gtf": "http://ftp.ensembl.org/pub/release-104/gtf/homo_sapiens/Homo_sapiens.GRCh38.104.gtf.gz",
    "vep_cache": f"https://ftp.ensembl.org/pub/release-{VEP_RELEASE}/variation/indexed_vep_cache/homo_sapiens_merged_vep_{VEP_RELEASE}_GRCh38.tar.gz",
    # See https://data.broadinstitute.org/Trinity/CTAT_RESOURCE_LIB/
}

reference_fname = settings["reference_url"].split("/")[-1][:-3]
reference_fai = os.path.basename(settings["reference_fai"])
reference_dict = os.path.splitext(reference_fname)[0] + ".dict"

gtf_file = os.path.splitext(os.path.basename(settings["gtf"]))[0]
gtf_renamed = os.path.splitext(gtf_file)[0] + ".chr.gtf"

vep_cache_fname = settings["vep_cache"].split("/")[-1]


rule all:
    input:
        fai=reference_fai,
        fasta_dict=reference_dict,
        refflat="ucsc_gencode.refFlat",
        bed_variant_hotspots="hotspots_genome.bed",
        vep_cache="homo_sapiens_merged",
        expression_gtf=gtf_renamed,
        itd_folder="itd",
        genome_fasta=reference_fname,
        star_index="star-index",
        ref_id_mapping="id_mappings.tsv",
        rrna_refflat="ucsc_rrna.refFlat",
        blacklist="blacklist.txt",
        arriba="arriba/protein_domains_hg38_GRCh38_v2.4.0.gff3",
        arriba_report_genes="arriba/report_genes.txt",


rule download_reference:
    output:
        fasta=reference_fname,
    params:
        url=settings["reference_url"],
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        rm -f {output.fasta}.gz &&
        wget {params.url} &&
        gzip -dc {output.fasta}.gz > {output.fasta}
        """


rule download_fai:
    output:
        reference_fai,
    params:
        settings["reference_fai"],
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        wget {params} -O {output}
        """


rule download_gtf:
    output:
        gtf_file,
    params:
        settings["gtf"],
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        wget {params} &&
        gunzip {output}.gz
        """


rule rewrite_gtf:
    """ Add the 'chr' prefix to the chromosome names """
    input:
        gtf=rules.download_gtf.output,
        rewrite=workflow.source_path("scripts/rewrite-gtf.py"),
    output:
        gtf=gtf_renamed,
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        {input.rewrite} {input.gtf} > {output.gtf}
        """


rule create_dict:
    input:
        rules.download_reference.output.fasta,
    output:
        reference_dict,
    singularity:
        containers["picard"]
    shell:
        """
        picard CreateSequenceDictionary R={input} O={output}
        """


rule create_star_index:
    input:
        fasta=rules.download_reference.output.fasta,
        gtf=rules.rewrite_gtf.output.gtf,
    params:
        overhang=149,
    output:
        directory("star-index"),
    singularity:
        containers["star"]
    shell:
        """
        rm -rf {output}
        mkdir {output}

        STAR \
            --runMode genomeGenerate \
            --genomeDir {output} \
            --genomeFastaFiles {input.fasta} \
            --sjdbGTFfile {input.gtf} \
            --sjdbOverhang {params.overhang}
        """


rule create_refflat:
    input:
        gtf=rules.rewrite_gtf.output,
    output:
        temporary("ucsc_gencode.refFlat.tmp"),
    singularity:
        containers["ucsc-gtftogenepred"]
    shell:
        """
        gtfToGenePred \
            -includeVersion \
            -geneNameAsName2 \
            -genePredExt {input.gtf} {output}
        """


rule rewrite_refflat:
    input:
        gtf=rules.create_refflat.output,
        scr=workflow.source_path("scripts/rewrite-refflat.py"),
    output:
        "ucsc_gencode.refFlat",
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        {input.scr} {input.gtf} > {output}
        """


rule create_id_mappings:
    input:
        workflow.source_path("small-files/id_mappings.tsv"),
    output:
        "id_mappings.tsv",
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        cp {input} {output}
        """


rule create_blacklist:
    input:
        workflow.source_path("small-files/blacklist.txt"),
    output:
        "blacklist.txt",
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        cp {input} {output}
        """


rule create_rRNA_refflat:
    """ Taken from https://gist.github.com/b8307038/55fb526e72141fac9f0aa2bc0e1f5997 """
    input:
        ref_dict=rules.create_dict.output,
        gtf=rules.rewrite_gtf.output,
    output:
        refflat="ucsc_rrna.refFlat",
    singularity:
        containers["hamlet-scripts"]
    shell:
        """

        # Include SQ headers to match the reference
        grep "^@SQ" {input.ref_dict} | cut -f 1,2,3 > {output.refflat}

        # Pattern to find rebozyme transcripts
        ribozyme='gene_biotype "rRNA"\|gene_biotype "Mt_rRNA"\|gene_biotype "Mt_tRNA"\|gene_biotype "ribozyme"'
        # Intervals for rRNA transcripts
        grep "$ribozyme" {input.gtf} | \
        awk '$3 == "gene"' | \
        cut -f1,4,5,7,9 | \
        perl -lane '
            /gene_id "([^"]+)"/ or die "no gene_id on $.";
            print join "\t", (@F[0,1,2,3], $1)
        ' | \
        sort -k1V -k2n -k3n >> {output.refflat}
        """


rule genome_hotspots:
    input:
        workflow.source_path("small-files/hotspots_genome.bed"),
    output:
        "hotspots_genome.bed",
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        cp {input} {output}
        """


rule create_report_genes:
    input:
        folder="arriba",
        genes=workflow.source_path("small-files/report_genes.txt"),
    output:
        "arriba/report_genes.txt",
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        cp {input.genes} {output}
        """


rule download_vep_cache:
    params:
        ftp=settings["vep_cache"],
        fname=vep_cache_fname,
    output:
        vep_cache_fname,
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        wget {params.ftp}
        """


rule unpack_vep_cache:
    input:
        rules.download_vep_cache.output,
    output:
        directory("homo_sapiens_merged"),
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        tar xzf {input}
        """


rule copy_itd:
    """All the needed files are in small-files/itd, so we just copy them"""
    input:
        fasta=workflow.source_path("small-files/itd/itd_genes.fa"),
    output:
        itd=directory("itd"),
    singularity:
        containers["hamlet-scripts"]
    shell:
        """
        in_dir=$(dirname {input.fasta})

        mkdir -p {output.itd}

        cp -v $in_dir/* {output.itd}
        """


rule arriba_database:
    output:
        folder=directory("arriba"),
        blacklist="arriba/blacklist_hg38_GRCh38_v2.4.0.tsv.gz",
        known_fusions="arriba/known_fusions_hg38_GRCh38_v2.4.0.tsv.gz",
        cytobands="arriba/cytobands_hg38_GRCh38_v2.4.0.tsv",
        protein_domains="arriba/protein_domains_hg38_GRCh38_v2.4.0.gff3",
    singularity:
        containers["arriba"]
    shell:
        """
        mkdir -p {output.folder}
        cp /usr/local/var/lib/{output.blacklist} {output.folder}
        cp /usr/local/var/lib/{output.known_fusions} {output.folder}
        cp /usr/local/var/lib/{output.cytobands} {output.folder}
        cp /usr/local/var/lib/{output.protein_domains} {output.folder}
        """
